{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "import load_approved_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_iters = 500\n",
    "n_cca_components = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in standard demographic data to pandas dataframe\n",
    "standard_data_filename = r'camcan_civet_ratings_combined.csv'\n",
    "standard_col_list = ['CCID','Age','Sex','Rating']\n",
    "standard_data = pd.read_csv(standard_data_filename, usecols=standard_col_list, index_col='CCID')\n",
    "\n",
    "#Change variable type - likely should move this later\n",
    "standard_data['Sex'] = standard_data['Sex'].astype('category')\n",
    "standard_data['Sex'] = standard_data['Sex'].cat.codes\n",
    "\n",
    "#filter out any columns which didn't meet approved rating\n",
    "#and then remove the rating column\n",
    "standard_data_filtered = standard_data[standard_data.Rating >= 0.5]\n",
    "standard_data_filtered = standard_data_filtered.drop(['Rating'], axis=1)\n",
    "#print (standard_data_filtered.head(5))\n",
    "\n",
    "#filter out any subjects under the age of 40\n",
    "standard_data_filtered = standard_data_filtered[standard_data_filtered.Age >= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in other demographic data to pandas dataframe\n",
    "approved_data_filename = r'Cam-CAN\\approved_data.tsv'\n",
    "#approved_col_list = ['CCID', 'homeint_handedness', 'additional_qual','homeint_v349']\n",
    "\n",
    "#approved_data = pd.read_csv(approved_data_filename, usecols=approved_col_list,  index_col='CCID', sep='\\t')\n",
    "approved_data = load_approved_data.load_approved_data(approved_data_filename)\n",
    "\n",
    "#print (approved_data.head(5))\n",
    "\n",
    "#merge data into one dataframe\n",
    "demographics = pd.merge(standard_data_filtered, approved_data, how='left', left_on='CCID', right_on='CCID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ccids = demographics.index.tolist()\n",
    "print(len(all_ccids))\n",
    "sample_ccids = resample(all_ccids, replace=True, random_state=0)\n",
    "print(len(sample_ccids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP ####\n",
    "# Remove these variables until figure out how to use them\n",
    "demographics.drop(['homeint_v96'], inplace=True, axis=1)\n",
    "demographics.drop(['homeint_v363'], inplace=True, axis=1)\n",
    "n_comp = demographics.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demographics.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demographics['Sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(approved_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in pca of vertices\n",
    "#vertexes_data_filename = r'Cam-CAN\\civet\\output\\output\\T1w_surface_rsl_left_native_volume_40mm_dataframe_comp.csv'\n",
    "component_file_location = r'C:\\Users\\grace\\Documents\\School\\Grad\\CoBrA\\Cam-CAN\\civet21\\native_rms_rsl_tlaplace_30mm_AAL.csv'\n",
    "#component_file_location = r'C:\\Users\\grace\\Documents\\School\\Grad\\CoBrA\\Cam-CAN\\civet21\\native_rms_rsl_tlaplace_30mm_left_ica_100.csv'\n",
    "\n",
    "vertexes = pd.read_csv(component_file_location, header=None)#.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vertexes.shape)\n",
    "print(demographics.shape)\n",
    "num_participants = demographics.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_model = CCA(n_components=50)\n",
    "cca_model.fit(demographics,vertexes)\n",
    "demographics_T, vertexes_T = cca_model.transform(demographics,vertexes)\n",
    "result = np.corrcoef(demographics_T.T, vertexes_T.T).diagonal(offset=cca_model.n_components)\n",
    "cc_corr = np.corrcoef(cca_model.x_scores_, rowvar=False).diagonal(offset=cca_model.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.plot(np.arange(cca_model.n_components)+1, result, 'ko')\n",
    "plt.xlim(.5, .5+cca_model.n_components)\n",
    "plt.xticks(np.arange(cca_model.n_components)+1)\n",
    "plt.xlabel('Canonical component')\n",
    "plt.ylabel('Canonical correlation')\n",
    "plt.title('Canonical correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cc_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = cca_model.predict(demographics)\n",
    "X_weights = cca_model.x_weights_\n",
    "X_loadings = cca_model.x_loadings_\n",
    "Y_weights = cca_model.y_weights_\n",
    "Y_loadings = cca_model.y_loadings_\n",
    "coefficients = cca_model.coef_\n",
    "\n",
    "my_coef_counts = dict()\n",
    "my_x_loadings = dict()\n",
    "for x_load in X_loadings.transpose():\n",
    "    print(x_load)\n",
    "    my_x_loadings[repr(x_load)] = 1\n",
    "for coef in coefficients:\n",
    "    #print(coef.shape)\n",
    "    #Note: use repr to convert coef to string since can't hash numpy array\n",
    "    my_coef_counts[repr(coef)] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefficients.shape)\n",
    "print(X_loadings.shape)\n",
    "print(len(my_x_loadings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexes_shuffled = shuffle(vertexes, random_state=1)\n",
    "#vertexes_shuffled = shuffle(vertexes)\n",
    "cca_model_shuffled = CCA(n_components=50)\n",
    "cca_model_shuffled.fit(demographics,vertexes_shuffled)\n",
    "coefficients_temp = cca_model_shuffled.coef_\n",
    "X_loadings_temp = cca_model_shuffled.x_loadings_\n",
    "Y_loadings_temp = cca_model_shuffled.y_loadings_\n",
    "demographics_s_T, vertexes_s_T = cca_model_shuffled.transform(demographics,vertexes_shuffled)\n",
    "result_shuffled = np.corrcoef(demographics_s_T.T, vertexes_s_T.T).diagonal(offset=cca_model_shuffled.n_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testcorrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrcoefs_bstrap = np.zeros((n_cca_components, bootstrap_iters))\n",
    "print(corrcoefs_bstrap.shape)\n",
    "fwe_vals = np.zeros((n_cca_components,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_shuffled, vertexes_shuffled = shuffle(demographics, vertexes, random_state=2)\n",
    "demographics_shuffled_split1 = demographics_shuffled[:num_participants//2]\n",
    "vertexes_shuffled_split1 = vertexes_shuffled[:num_participants//2]\n",
    "demographics_shuffled_split2 = demographics_shuffled[num_participants//2:]\n",
    "vertexes_shuffled_split2 = vertexes_shuffled[num_participants//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_shuffled_split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_shuffled_split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_model_shuffled_split2 = CCA(n_components=50)\n",
    "cca_model_shuffled_split2.fit(demographics_shuffled_split2,vertexes_shuffled_split2)\n",
    "coefficients_temp = cca_model_shuffled_split2.coef_\n",
    "X_loadings_temp_split2 = cca_model_shuffled_split2.x_loadings_\n",
    "Y_loadings_temp_split2 = cca_model_shuffled_split2.y_loadings_\n",
    "X_weights_temp_split2 = cca_model_shuffled_split2.x_weights_\n",
    "Y_weights_temp_split2 = cca_model_shuffled_split2.y_weights_\n",
    "test1_c, test2_c = cca_model_shuffled_split2.transform(demographics_shuffled_split2, vertexes_shuffled_split2)\n",
    "testcorrs_split2 = np.corrcoef(test1_c.T, test2_c.T).diagonal(offset=cca_model_shuffled_split2.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_model_shuffled_split1 = CCA(n_components=50)\n",
    "cca_model_shuffled_split1.fit(demographics_shuffled_split1,vertexes_shuffled_split1)\n",
    "coefficients_temp = cca_model_shuffled_split1.coef_\n",
    "X_loadings_temp_split1 = cca_model_shuffled_split1.x_loadings_\n",
    "Y_loadings_temp_split1 = cca_model_shuffled_split1.y_loadings_\n",
    "X_weights_temp_split1 = cca_model_shuffled_split1.x_weights_\n",
    "Y_weights_temp_split1 = cca_model_shuffled_split1.y_weights_\n",
    "test1_c, test2_c = cca_model_shuffled_split1.transform(demographics_shuffled_split1, vertexes_shuffled_split1)\n",
    "testcorrs_split1 = np.corrcoef(test1_c.T, test2_c.T).diagonal(offset=cca_model_shuffled_split1.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(X_loadings_temp_split2-X_loadings_temp_split1))\n",
    "print(np.linalg.norm(Y_loadings_temp_split2-Y_loadings_temp_split1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(X_weights_temp_split2-X_weights_temp_split1))\n",
    "print(np.linalg.norm(Y_weights_temp_split2-Y_weights_temp_split1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(a,b):\n",
    "    \"Calculates the Levenshtein distance between a and b.\"\n",
    "    n, m = len(a), len(b)\n",
    "    if n > m:\n",
    "        # Make sure n <= m, to use O(min(n,m)) space\n",
    "        a,b = b,a\n",
    "        n,m = m,n\n",
    "        \n",
    "    current = range(n+1)\n",
    "    for i in range(1,m+1):\n",
    "        previous, current = current, [i]+[0]*n\n",
    "        for j in range(1,n+1):\n",
    "            add, delete = previous[j]+1, current[j-1]+1\n",
    "            change = previous[j-1]\n",
    "            if a[j-1] != b[i-1]:\n",
    "                change = change + 1\n",
    "            current[j] = min(add, delete, change)\n",
    "            \n",
    "    return current[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testcorrs_split1)\n",
    "print(testcorrs_split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#vertexes_shuffled = shuffle(vertexes)\n",
    "cca_model_shuffled = CCA(n_components=50)\n",
    "cca_model_shuffled.fit(demographics,vertexes_shuffled)\n",
    "coefficients_temp = cca_model_shuffled.coef_\n",
    "X_loadings_temp = cca_model_shuffled.x_loadings_\n",
    "Y_loadings_temp = cca_model_shuffled.y_loadings_\n",
    "test1_c, test2_c = cca_model_shuffled.transform(demographics, vertexes_shuffled)\n",
    "testcorrs = np.corrcoef(test1_c.T, test2_c.T).diagonal(offset=cca_model_shuffled.n_components)\n",
    "corrcoefs_bstrap[:,b_iter] = testcorrs\n",
    "\"\"\"\n",
    "for coef in coefficients_temp:\n",
    "    coef_hashable = repr(coef)\n",
    "    if coef_hashable in my_coef_counts:\n",
    "        my_coef_counts[coef_hashable] += 1\n",
    "    else:\n",
    "        my_coef_counts[coef_hashable] = 1\n",
    "for x_load in X_loadings_temp.transpose():\n",
    "    x_load_hashable = repr(x_load)\n",
    "    if x_load_hashable in my_x_loadings:\n",
    "        my_x_loadings[x_load_hashable] += 1\n",
    "    else:\n",
    "        my_x_loadings[x_load_hashable] = 1\n",
    "\"\"\"\n",
    "if b_iter % 100 == 0:\n",
    "    print(str(b_iter) + \" at \" + time.ctime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrcoefs_bstrap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp_x in range(0,n_cca_components):\n",
    "    corr_x = result[comp_x]\n",
    "    temp_compare = np.zeros(bootstrap_iters)\n",
    "    for b_iter in range(0,bootstrap_iters):\n",
    "        if corr_x < corrcoefs_bstrap[0,b_iter]:\n",
    "            temp_compare[b_iter] = 1\n",
    "        else:\n",
    "            temp_compare[b_iter] = 0\n",
    "    fwe_vals[comp_x] = (1+sum(temp_compare))/bootstrap_iters\n",
    "    #print(temp_compare)\n",
    "    #print(corr_x, fwe_vals[comp_x])\n",
    "print(fwe_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrcoefs_bstrap)\n",
    "print(corrcoefs_bstrap.shape)\n",
    "print(corrcoefs_bstrap[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(my_coef_counts.values()))\n",
    "#print(get_key(my_coef_counts,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(my_x_loadings.values()))\n",
    "#print(get_key(my_coef_counts,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demographics_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefficients.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_times_pc_selected = np.zeros(vertexes.shape[1])\n",
    "abs_val_pc_selected = np.zeros(vertexes.shape[1])\n",
    "total_times_dem_selected = np.zeros(demographics.shape[1])\n",
    "abs_val_dem_selected = np.zeros(demographics.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_val_dem_selected = np.sum(np.absolute(X_loadings),axis=1)\n",
    "abs_val_pc_selected = np.sum(np.absolute(Y_loadings),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(0,63)), abs_val_dem_selected)\n",
    "plt.show()\n",
    "plt.bar(list(range(0,100)), abs_val_pc_selected)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(max(X_weights[:,0]))\n",
    "#print(X_weights[:,0])\n",
    "#print(X_loadings[:,0])\n",
    "#print(max(X_loadings[:,0]))\n",
    "#print(X_weights[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(X_loadings[:,0]))\n",
    "print(max(X_loadings[:,0]))\n",
    "\n",
    "for ix in range(0,len(X_weights[:,0])):\n",
    "    val = X_weights[ix,0]\n",
    "    if val > 0.1 or val <-0.1:\n",
    "        print(ix)\n",
    "        print(demographics.columns[ix] + \" : \" + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(X_loadings[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_indices = 1\n",
    "cc_cal = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top \" + str(n_indices) + \" pos weighted\")\n",
    "for current_cc_cal in range(0,cc_cal+1):\n",
    "    X_max_idx = np.argpartition(X_loadings[:,current_cc_cal], -n_indices)[-n_indices:]\n",
    "    X_max_indices = X_max_idx[np.argsort((-X_loadings[:,current_cc_cal])[X_max_idx])]\n",
    "    #print(X_max_indices)\n",
    "    dc_mi1 = demographics.columns[X_max_indices[0]]\n",
    "    dc_mi2 = demographics.columns[X_max_indices[1]]\n",
    "    dc_mi3 = demographics.columns[X_max_indices[2]]\n",
    "    dc_mi4 = demographics.columns[X_max_indices[3]]\n",
    "\n",
    "    dict_col_names = pd.read_csv(r'Cam-CAN\\approved_col_headers.csv', index_col=0).T.to_dict('list')\n",
    "    for key in dict_col_names:\n",
    "        val_tostring_temp = dict_col_names[key][0]\n",
    "        dict_col_names[key] = val_tostring_temp\n",
    "    dict_col_names['Age'] = ''\n",
    "    dict_col_names['Sex'] = ''\n",
    "\n",
    "    print(\"CC \" + str(current_cc_cal+1) + \": \" + dc_mi1 + \" (\" + dict_col_names[dc_mi1] + \"), \" + dc_mi2 + \" (\" + dict_col_names[dc_mi2] + \"), \" + dc_mi3 + \" (\" + dict_col_names[dc_mi3] + \"), \" + dc_mi4 + \" (\" + dict_col_names[dc_mi4] + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top \" + str(n_indices) + \" neg weighted\")\n",
    "for current_cc_cal in range(0,cc_cal+1):\n",
    "    X_min_idx = np.argpartition(X_loadings[:,current_cc_cal], n_indices)[:n_indices]\n",
    "    X_min_indices = X_min_idx[np.argsort((X_loadings[:,current_cc_cal])[X_min_idx])]\n",
    "    #print(X_min_indices)\n",
    "    \n",
    "    dc_mi1 = demographics.columns[X_min_indices[0]]\n",
    "    dc_mi2 = demographics.columns[X_min_indices[1]]\n",
    "    dc_mi3 = demographics.columns[X_min_indices[2]]\n",
    "    dc_mi4 = demographics.columns[X_min_indices[3]]\n",
    "\n",
    "    dict_col_names = pd.read_csv(r'Cam-CAN\\approved_col_headers.csv', index_col=0).T.to_dict('list')\n",
    "    for key in dict_col_names:\n",
    "        val_tostring_temp = dict_col_names[key][0]\n",
    "        dict_col_names[key] = val_tostring_temp\n",
    "    dict_col_names['Age'] = ''\n",
    "    dict_col_names['Sex'] = ''\n",
    "\n",
    "    print(\"CC \" + str(current_cc_cal+1) + \": \" + dc_mi1 + \" (\" + dict_col_names[dc_mi1] + \"), \" + dc_mi2 + \" (\" + dict_col_names[dc_mi2] + \"), \" + dc_mi3 + \" (\" + dict_col_names[dc_mi3] + \"), \" + dc_mi4 + \" (\" + dict_col_names[dc_mi4] + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top \" + str(n_indices) + \" pos weighted\")\n",
    "for current_cc_cal in range(0,cc_cal+1):\n",
    "    Y_max_idx = np.argpartition(Y_loadings[:,current_cc_cal], -n_indices)[-n_indices:]\n",
    "    Y_max_indices = Y_max_idx[np.argsort((-Y_loadings[:,current_cc_cal])[Y_max_idx])]\n",
    "    print(\"CC \" + str(current_cc_cal+1) + \": \" + str(Y_max_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top \" + str(n_indices) + \" neg weighted\")\n",
    "for current_cc_cal in range(0,cc_cal+1):\n",
    "    Y_min_idx = np.argpartition(Y_loadings[:,current_cc_cal], n_indices)[:n_indices]\n",
    "    Y_min_indices = Y_min_idx[np.argsort((Y_loadings[:,current_cc_cal])[Y_min_idx])]\n",
    "    print(\"CC \" + str(current_cc_cal+1) + \": \" + str(Y_min_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_max_idx = np.argpartition(Y_loadings[:,cc_cal], -n_indices)[-n_indices:]\n",
    "Y_max_indices = Y_max_idx[np.argsort((-Y_loadings[:,cc_cal])[Y_max_idx])]\n",
    "print(Y_max_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_min_idx = np.argpartition(Y_loadings[:,cc_cal], n_indices)[:n_indices]\n",
    "Y_min_indices = Y_min_idx[np.argsort((Y_loadings[:,cc_cal])[Y_min_idx])]\n",
    "print(Y_min_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max1 = max(X_loadings[:,0])\n",
    "max2 = max(X_loadings[:,0].delete(max1))\n",
    "max3 = max(X_loadings[:,0].delete(max1))\n",
    "print(X_loadings[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_weights.shape)\n",
    "print(max(Y_loadings[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zxcv = \"Age Sex Handedness HouseholdSize SocialLife1 SocialLife2 SocialLife3 SocialLife4 SocialLife5 SocialLife6 SocialLife7 SocialLife8 SocialLife9 HearingDifficulties1 HearingDifficulties2 HearingDifficulties3 BloodPressure1 BloodPressur2 BloodPressure3 BloodPressure4 BloodPressure5 BloodPressure6 HighCholesterol1 HighCholesterol2 Angina1 Angina2 HeartAttack1 HeartAttack2 CardiacIssues1 CardiacIssues2 VaricoseVeins1 VaricoseVeins2 Migraines1 Migraines2 Stroke1 Stroke2 PulmonaryEmbolism1 PulmonaryEmbolism2 DeepVeinThrombosis1 DeepVeinThrombosis2 VascularDisease1 VascularDisease2 Diabetes1 Diabetes2 Anxiety HeadInjury1 HeadInjury2 HeadInjury3 HeadInjury4 SkullFracture AdDiagnosis MMSEScore PhysicalActivityHrs PhysicalActivityEnergy PhysicalActivityTotal PhysicalActivityOther Smoking Alcohol Depression1 Depression2 Education SocialClass EconomicGroup\"\n",
    "listzxcv = zxcv.split(\" \")\n",
    "print(listzxcv)\n",
    "print(len(listzxcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demographics.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(0,100)), Y_loadings[:,0])\n",
    "counter = 0\n",
    "for y_load in Y_loadings[:,0]:\n",
    "    counter +=1 \n",
    "    if y_load > 0.15:\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize number of samples\n",
    "nSamples = 1000\n",
    "\n",
    "# Define two latent variables (number of samples x 1)\n",
    "latvar1 = np.random.randn(nSamples,)\n",
    "latvar2 = np.random.randn(nSamples,)\n",
    "\n",
    "# Define independent components for each dataset (number of observations x dataset dimensions)\n",
    "indep1 = np.random.randn(nSamples, 4)\n",
    "indep2 = np.random.randn(nSamples, 5)\n",
    "\n",
    "# Create two datasets, with each dimension composed as a sum of 75% one of the latent variables and 25% independent component\n",
    "data1 = 0.25*indep1 + 0.75*np.vstack((latvar1, latvar2, latvar1, latvar2)).T\n",
    "data2 = 0.25*indep2 + 0.75*np.vstack((latvar1, latvar2, latvar1, latvar2, latvar1)).T\n",
    "\n",
    "# Split each dataset into two halves: training set and test set\n",
    "train1 = data1[:nSamples//2]\n",
    "train2 = data2[:nSamples//2]\n",
    "test1 = data1[nSamples//2:]\n",
    "test2 = data2[nSamples//2:]\n",
    "\n",
    "# Create a cca object as an instantiation of the CCA object class. \n",
    "nComponents = 4\n",
    "cca_l = CCA(n_components=nComponents)\n",
    "\n",
    "# Use the train() method to find a CCA mapping between the two training sets.\n",
    "cca_l.fit(train1, train2)\n",
    "\n",
    "# Use the validate() method to test how well the CCA mapping generalizes to the test data.\n",
    "# For each dimension in the test data, correlations between predicted and actual data are computed.\n",
    "test1_c, test2_c = cca_l.transform(train1, train2)\n",
    "testcorrs = np.corrcoef(test1_c.T, test2_c.T).diagonal(offset=nComponents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(0,63)), X_loadings[:,0])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,1])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,2])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,3])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,4])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,5])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,6])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,7])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,8])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,63)), X_loadings[:,9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(0,18)), Y_loadings[:,0])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,1])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,2])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,3])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(0,18)), Y_loadings[:,5])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,6])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,7])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,8])\n",
    "plt.show()\n",
    "plt.bar(list(range(0,18)), Y_loadings[:,9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_loadings[:,0].shape)\n",
    "plt.bar(list(range(0,100)), Y_loadings[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "tempyvals = []\n",
    "for i in range(0,63):\n",
    "    n = random.uniform(-4, 4)\n",
    "    tempyvals.append(n)\n",
    "tempyvals[3] = 0\n",
    "tempyvals[10] = 0\n",
    "tempyvals[11] = 0\n",
    "tempyvals[12] = 0\n",
    "tempyvals[28] = 0\n",
    "tempyvals[30] = 0\n",
    "tempyvals[42] = 0\n",
    "tempyvals[59] = 0\n",
    "plt.bar(list(range(0,63)), tempyvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Cam-CAN\\approved_col_headers.csv', newline='') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        names_of_demos = [row[1].replace(\" \", \"\") for row in reader if row and row[1]!=\"\"]\n",
    "names_of_demos = ['Age', 'Sex'] + names_of_demos[1:]\n",
    "print(names_of_demos)\n",
    "print(demographics.columns)\n",
    "print(len(names_of_demos))\n",
    "print(demographics.columns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_headers_positive = [x for bleep,x in sorted(zip(X_loadings[:,0],listzxcv)) if bleep >= 0][::-1]\n",
    "print(sorted_headers_positive)\n",
    "sorted_headers_negative = [x for bleep,x in sorted(zip(X_loadings[:,0],listzxcv)) if bleep < 0]\n",
    "print(sorted_headers_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "largest_cc1 = heapq.nlargest(10,X_loadings[:,0])\n",
    "cc1_idx1 = np.where(X_loadings[:,0] == largest_cc1[0])\n",
    "print(largest_cc1)\n",
    "print(demographics.columns[cc1_idx1])\n",
    "print('------')\n",
    "smallest_cc1 = heapq.nsmallest(10,X_loadings[:,0])\n",
    "cc1_idxneg1 = np.where(X_loadings[:,0] == smallest_cc1[0])\n",
    "cc1_idxneg2 = np.where(X_loadings[:,0] == smallest_cc1[1])\n",
    "print(smallest_cc1)\n",
    "print(demographics.columns[cc1_idxneg1])\n",
    "print(demographics.columns[cc1_idxneg2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
